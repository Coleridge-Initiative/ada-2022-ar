{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><br><br>\n",
    "    Arkansas Work-Based Learning to Workforce Outcomes <br>\n",
    "    Applied Data Analytics Training | Spring 2022\n",
    "    <h1> Presentation Preparation </h1>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Coleridge Initiative</a>\n",
    "    </span>\n",
    "    <center>Joshua Edelmann and Benjamin Feder</center>\n",
    "</center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides information on how to prepare research output for disclosure control. It outlines how to prepare different kinds of outputs before submitting an export request and gives an overview of the information needed for disclosure review. _Please read through the entire notebook because it will separately discuss all types of outputs that will be flagged in the disclosure review process._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR 2022 Class Export Review Guidelines \n",
    "\n",
    "- **Each team will be able to export up to 10 figures/tables**\n",
    "    \n",
    "    \n",
    "- **Every statistic for export must be based on at least 11 individuals and at least 3 employers (when using wage records)**\n",
    "     - Statistics that are based off of 0-10 individuals must be supressed\n",
    "     - Statistics that are based off of 0-2 employers must be supressed\n",
    "    \n",
    "    \n",
    "- **All counts will need to be rounded**\n",
    "    - Counts below 1000 should be rounded to the nearest ten\n",
    "    - Counts greater than or equal to 1000 should be rounded to the nearest hundred\n",
    "    > For example, a count of 868 would be rounded to 870 and a count of 1868 would be rounded to 1900\n",
    "\n",
    "- **All reported wages will need to be rounded to the nearest hundred** \n",
    "    \n",
    "- **All reported averages will need to be rounded to the nearest hundredth** \n",
    "   \n",
    "- **All percentages and proportions need to be rounded**\n",
    "    - The same rounding rule that is applied to counts must be applied to both the numerator and denominator\n",
    "    - Percentages must then be rounded to the nearest percent\n",
    "    - Proportions must be rounded to the nearest hundredth\n",
    "\n",
    "\n",
    "- **Exact percentiles can not be exported** \n",
    "    - Instead, for example, you may calculate a “fuzzy median”, by averaging the true 45th and 55th percentiles\n",
    "       - If you are calculating the fuzzy percentiles for wage, you will need to round to the nearest hundred after calculating the fuzzy percentile\n",
    "       - If you are calculating the fuzzy percentile for a number of individuals, you will need to round to the nearest 10 if the count is less than 1000 and to the nearest hundred if the count is greater than or equal to 1000\n",
    "  \n",
    "- **Exact Maxima and Minima can not be exported**\n",
    "    - Suppress maximum and minimum values in general\n",
    "    - You may replace an exact maximum or minimum with a top-coded value or a fuzzy maximum or minimum value. For example: If the maximum value for earnings is 154,325, it could be top-coded as '100,000+'. And a fuzzy maximum value could be: \n",
    "    $$\\frac{95th\\ percentile\\ of\\ earnings + 154325}{2}$$\n",
    " \n",
    " \n",
    "- **Complementary suppression**\n",
    "    - If your figures include totals or are dependent on a preceding or subsequent figures, you need to take into account complementary disclosure risks—that is, whether the figure totals or the separate figures when read together, might disclose information about less then 11 individuals in the data in a way that a single, simpler table would not. Team facilitators and export reviewers will work with you by offering guidance on implementing any necessary complementary suppression techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Supporting Documentation for Exports\n",
    "\n",
    "For each exported figure, you will need to provide a table with **underlying counts** of individuals and employers (when appropriate) for each statistic depicted in the figure. \n",
    "\n",
    "- You will need to include both the rounded and the unrounded counts of individuals\n",
    "\n",
    "- If percentages or proportions are to be exported, you must report both the rounded and the unrounded counts of individuals for the numerator and denominator. You must also report the counts of employers for both the numerator and the denominator when working with wage records\n",
    "\n",
    "**Code**\n",
    "- Please provide the code for every output that needs to be exported and the code generating every table (csv) with underlying counts. It is important for the ADRF staff to have the code to better understand what exactly was done and to be able to replicate results. Understanding how research results are created is important in understanding the research output. Thus, it is important to document every step of the analysis in the Jupyter notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "In this notebook, we will show you how to implement the above export rules while creating the necessary input files and supporting code to create beautiful visuals that are presentation ready. \n",
    "\n",
    "We will cover the following visualizations in this notebook:\n",
    "- **Bar Plot**: visualizes relationships between numerical and categorical variables\n",
    "- **Bar Plot with distribution bars**: visualizes relationships between numerical and categorical variables\n",
    "- **Line Plot**: is commonly used for time series data to show how a variable changes over time\n",
    "- **Heat Map**: visualizes density\n",
    "\n",
    ">  Note: Throughout this notebook, we will use colors from the following colorblind-friendly palette:\n",
    "    \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#999999\", \"#E69F00\",  \"#56B4E9\", \"#F0E442\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switching off warnings\n",
    "options(warn=-1)\n",
    "\n",
    "#database interaction imports\n",
    "suppressMessages(library(odbc))\n",
    "\n",
    "# for data manipulation/visualization\n",
    "suppressMessages(library(tidyverse))\n",
    "\n",
    "# scaling data, calculating percentages, overriding default graphing\n",
    "suppressMessages(library(scales))\n",
    "\n",
    "# to better view images\n",
    "# For easier viewing of graphs\n",
    "# Adjust repr.plot.width and repr.plot.height to change the size of graphs\n",
    "theme_set(theme_gray(base_size = 24))\n",
    "options(repr.plot.width = 20, repr.plot.height = 12)\n",
    "options(warn=0)\n",
    "\n",
    "# to avoid scientific notation\n",
    "options(scipen = 999) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "con <- DBI::dbConnect(odbc::odbc(),\n",
    "                     Driver = \"SQL Server\",\n",
    "                     Server = \"msssql01.c7bdq4o2yhxo.us-gov-west-1.rds.amazonaws.com\",\n",
    "                     Trusted_Connection = \"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Information\n",
    "For our first visual, we will create a barplot that will summarise information about our cohort of interest. In this example, we will visualize the number of individuals who completed apprenticeships in the five most common industries by race. As a reminder, our cohort consists of apprenticeship completers in Arkansas between 2015 and 2017. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprenticeship industry and race information for our cohort can be found in the **nb_cohort** table. In the following query, we will read in the **tr_ar_2022.dbo.nb_cohort** table we created in the `02_Creating_a_cohort.ipynb`  notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query <- \"\n",
    "SELECT *\n",
    "FROM tr_ar_2022.dbo.nb_cohort nb;\n",
    "\"\n",
    "cohort <- dbGetQuery(con, query)\n",
    "\n",
    "head(cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will look at our cohort broken down by race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we can use count() since we know there is one row per person\n",
    "cohort %>%\n",
    "    count(race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are fewer than 11 individuals who identify as Asian, Native Hawaiian or Other Pacific Islander, and those that do not wish to answer.  Given that the RAPIDS data is public information, though, the export rules do not apply; thus, we will not need to further aggregate (or eventually round). However, once we link these data to any of the confidential Arkansas microdata (even the crosswalk), we will have to combine these categories to make it possible to export the data.\n",
    "\n",
    "We suggest aggregating these race variables. Here, for strictly pedagogical purposes, we will create a binary variable for white and non-white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort <- cohort %>%\n",
    "    # categorical variable \n",
    "    mutate(binary_race = ifelse(race != \"White\" | is.na(race), \"Non-White\", \"White\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to find the five most common apprenticeship industries for our cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_naics <- cohort %>%\n",
    "    count(Name) %>%\n",
    "    arrange(desc(n)) %>%\n",
    "    # rename to track total individuals\n",
    "    rename(total_n = n) %>%\n",
    "    slice(1:5)\n",
    "\n",
    "top_naics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's count the number of individuals by the binary race variable within each of these five industries. In cases where we are working with data assets based on any of the protected Arkansas datasets, we would need to make sure we have at least 11 individuals per subgroup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see counts by Name/binary_race\n",
    "# keeping total_n in for future sorting in graph\n",
    "cohort %>%\n",
    "    inner_join(top_naics, by = 'Name') %>%\n",
    "    count(binary_race, Name, total_n) %>%\n",
    "    arrange(binary_race, desc(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for Export\n",
    "\n",
    "In general, for each figure/table you create, you should prepare the data for the supplementary table, and then use that data to produce the figure/table. However, since our findings are limited to public data at the moment, we do not need to build a supplemental table containing the counts of individuals (and potentially employers) by data point, and we also do not need to suppress or round any of the values.\n",
    "\n",
    "Let's still save the underlying table for visualization as a separate data frame.\n",
    "> Note: If a file for export request only uses public data, be sure to make this clear for the export reviewers in your export documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_1_data <- cohort %>%\n",
    "    inner_join(top_naics, by = 'Name') %>%\n",
    "    count(binary_race, Name, total_n) %>%\n",
    "    arrange(binary_race, desc(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data: Bar Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared the underlying data for the visualization, we can use the following code to create a bar plot that depicts our cohort broken down by common apprenticeship industries and our binary race variable. When creating this graph, we want to compare our 2 catagories based on the most common apprenticeship industries. Since the comparison variable is **binary_race**, that is what we will input in the `fill` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colorblind-safe colors in a vector\n",
    "binary_value_color <- c('Non-White' = \"#009E73\", 'White' = \"#0072B2\" ) \n",
    "binary_value_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_1_data %>%\n",
    "               # naics on the x-axis, order by most common for entire cohort\n",
    "    ggplot(aes(x = reorder(Name, total_n), \n",
    "               # count on the y-axis\n",
    "               y = n, \n",
    "               # filling bars based on binary_race categories\n",
    "               fill = binary_race)) +\n",
    "    geom_bar(stat = \"identity\", position = 'dodge') +\n",
    "    scale_fill_manual(\"Binary Race Indicator\", values = binary_value_color) + # label legend and assign color palette \n",
    "    labs(\n",
    "        x = 'Industry', # labelling x axis\n",
    "        y = 'Number of Individuals', # labelling y axis\n",
    "        # Add a title that conveys the main takeaway of the graph\n",
    "        title = 'Race Distribution Amongst Most Common Industries Differs for Apprenticeship Completers', # \\n splits the title into two lines to avoid getting cut off if needed\n",
    "        caption = 'Source: RAPIDS Data' # cite the source of your data\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is hard to read the industry descriptions due to overlap. Let's shorten them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten industry descriptions\n",
    "# using TRUE at the end because it is the last category\n",
    "# note that \"Commerical and Institutional Building Construction\" has an extra space, can trim all whitespace as well\n",
    "Figure_1_data <- Figure_1_data %>%\n",
    "    mutate(\n",
    "        Name = case_when(\n",
    "            Name == 'Painting and Wall Covering Contractors' ~ 'Painting Contractor',\n",
    "            Name == 'Commercial and Institutional Building Construction ' ~ 'Commercial Construction',\n",
    "            Name == 'Electrical Contractors and Other Wiring Installation Contractors' ~ 'Electrical Contractor',\n",
    "            Name == 'Finish Carpentry Contractors' ~ 'Carpentry Contractor',\n",
    "            TRUE ~ 'Appliance Contractor'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_1 <- Figure_1_data %>%\n",
    "               # naics on the x-axis, order by most common for entire cohort\n",
    "    ggplot(aes(x = reorder(Name, total_n), \n",
    "               # count on the y-axis\n",
    "               y = n, \n",
    "               # filling bars based on binary_race categories\n",
    "               fill = binary_race)) +\n",
    "    geom_bar(stat = \"identity\", position = 'dodge') +\n",
    "    scale_fill_manual(\"Binary Race Indicator\", values = binary_value_color) + # label legend and assign color palette \n",
    "    labs(\n",
    "        x = 'Industry', # labelling x axis\n",
    "        y = 'Number of Individuals', # labelling y axis\n",
    "        # Add a title that conveys the main takeaway of the graph\n",
    "        title = 'Race Distribution Amongst Most Common Industries Differs for Apprenticeship Completers', # \\n splits the title into two lines to avoid getting cut off if needed\n",
    "        caption = 'Source: RAPIDS Data' # cite the source of your data\n",
    "    ) \n",
    "\n",
    "# see plot\n",
    "Figure_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Font Sizes\n",
    "In order to make the plot presentation ready, we advise using readable font sizes, as the image will be added to either a presentation or report. Additionally, since the NAICS descriptions still long, it may make sense to rotate the labels to improve the readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_1 <- Figure_1 + \n",
    "    theme(\n",
    "        legend.text = element_text(size = 24), # legend text font size\n",
    "        legend.title = element_text(size = 24), # legend title font size\n",
    "        axis.text.x = element_text(size = 24), # x axis label font size\n",
    "        axis.title.x = element_text(size = 24), # x axis title font size\n",
    "        axis.text.y = element_text(size = 24), # y axis label font size\n",
    "        axis.title.y = element_text(size = 24) # y axis title font size\n",
    "    ) + \n",
    "    scale_x_discrete(\n",
    "        guide = guide_axis(angle = 45) # rotate x-axis labels\n",
    "    )\n",
    "\n",
    "# Display the graph that we just created\n",
    "Figure_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Wage Quantiles\n",
    "\n",
    "You might not want a figure that only shows number of individuals broken down by apprenticeship industry and a binary race variable, and want to convey information about the distribution of primary employment wages by race relative to the quarter after apprenticeship completion. \n",
    "\n",
    "To do so, we will eventually create a bar graph where each bar will represent a fuzzy median, and we will include distribution bars on each bar that represent the fuzzy 25th and 75th quantiles of the wages for each grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Export\n",
    "\n",
    "We will adhere to the following steps in preparing this visualization for export:\n",
    "\n",
    "1. Create fuzzy percentiles\n",
    "    - Fuzzy 25th percentile: Calculate the 20th and 30th percentiles and take the average \n",
    "    - Fuzzy median : Calculate the 45th and 55th percentiles and take the average\n",
    "    - Fuzzy 75th percentile: Calculate the 70th and 80th percentiles and take the average\n",
    "\n",
    "To get the average, we add the percentiles together and divide by 2. For example:\n",
    "$$fuzzy\\  25th\\ = \\frac{20th + 30th}{2}$$\n",
    "\n",
    "2. Redact values \n",
    "    - Values with employer counts below 3 and/or individual counts below 11 must be removed\n",
    "\n",
    "3. Round values\n",
    "    - Counts below 1000 should be rounded to the nearest ten\n",
    "    - Counts above or equal to 1000 should be rounded to the nearest hundred\n",
    "    - Wages must be rounded to the nearest hundred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for Export\n",
    "\n",
    "Recall that the data frame **cohort** only contains information from RAPIDS - in order to answer this question, we will need to bring in information from the wage records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry <- \"\n",
    "SELECT C.race,\n",
    "F.Quarter_ID - P.Apprenticeship_End_Quarter_ID AS Quarters_Relative_to_Completion,\n",
    "P.Person_ID,\n",
    "F.Primary_Employer_Wages ,\n",
    "PE.Federal_EIN,\n",
    "C.apprnumber --pulling in for later\n",
    "FROM \n",
    "tr_ar_2022.dbo.nb_cohort C --COHORT\n",
    "JOIN tr_ar_2022.dbo.AR_MDIM_Person P ON (P.Apprentice_Number=C.apprnumber) --PERSON\n",
    "JOIN tr_ar_2022.dbo.AR_FACT_Quarterly_Observation F --QUARTERLY OBSERVATION FACT\n",
    "    ON (P.Person_ID=F.Person_ID) \n",
    "    AND (F.Quarter_ID BETWEEN (P.Apprenticeship_End_Quarter_ID + 1) AND (P.Apprenticeship_End_Quarter_ID+4))  --QTRS POST COMPLETION\n",
    "JOIN tr_ar_2022.dbo.AR_RDIM_NAICS_National_Industry NNI ON (P.Apprenticeship_NAICS_National_Industry_ID=NNI.NAICS_National_Industry_ID) --APPRENTICESHIP INDUSTRY\n",
    "JOIN tr_ar_2022.dbo.AR_MDIM_Employer PE ON (PE.Employer_ID=F.Primary_Employer_ID)  --PRIMARY EMPLOYER\n",
    "\"\n",
    "\n",
    "# create binary race variable\n",
    "cohort_wages <- dbGetQuery(con, qry) %>%\n",
    "    mutate(binary_race = ifelse(race != \"White\" | is.na(race), \"Non-White\", \"White\"))\n",
    "    \n",
    "head(cohort_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply our disclosure rules to our table by including the rules in the `ifelse()` statement below. We can also apply our rounding rules.\n",
    "\n",
    "> Note: We are replacing all values that do not satisfy our disclosure rules with `NA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round and apply disclosure rules\n",
    "# first calculating fuzzy medians and finding number of unique individuals and employers\n",
    "Figure_2_data <-  cohort_wages %>%\n",
    "    group_by(Quarters_Relative_to_Completion,binary_race) %>%\n",
    "    summarise(\n",
    "        individuals = n_distinct(Person_ID),\n",
    "        employers = n_distinct(Federal_EIN),\n",
    "        # fuzzy 25th percentile\n",
    "        fuzzy_25 = (quantile(Primary_Employer_Wages, .20) + quantile(Primary_Employer_Wages, .30))/2,\n",
    "        # fuzzy median (50th percentile)\n",
    "        fuzzy_median = (quantile(Primary_Employer_Wages, .45) + quantile(Primary_Employer_Wages, .55))/2,\n",
    "        # fuzzy 75th percentile\n",
    "        fuzzy_75 = (quantile(Primary_Employer_Wages, .70) + quantile(Primary_Employer_Wages, .80))/2\n",
    "    ) %>%\n",
    "    ungroup() %>%\n",
    "    # if the subgroup satisfies disclosure rules (using unrounded values), round to nearest 100\n",
    "    # otherwise redact\n",
    "    mutate(\n",
    "        fuzzy_25_rounded = ifelse(individuals < 11 | employers < 3, NA, round(fuzzy_25, -2)),\n",
    "        fuzzy_median_rounded = ifelse(individuals < 11 | employers < 3, NA, round(fuzzy_median, -2)),\n",
    "        fuzzy_75_rounded = ifelse(individuals < 11 | employers < 3, NA, round(fuzzy_75, -2))\n",
    "    )\n",
    "\n",
    "Figure_2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame now has all of the necessary underlying information for export review, and because it has been built based in part on the protected microdata, we will need to include it in the export submission. Let's save this data frame as a csv.\n",
    "\n",
    "This table will not be exported, it will be used by the export team to make sure the figure passes the disclosure requirments. As in this example, all supporting tables should be generated programmatically (using only code) and the associated figure should be generated only using data that correspond to that table.\n",
    "\n",
    "> **Note: In order to save the data in this way, you will need a folder called \"Data\" in the same folder that contains your code/notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(Figure_2_data, \"Data/Figure_2_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although none of the rows needed to be primarily suppressed, some of these rows may need to be suppressed when evaluated in combination with other files. Your team lead and export reviewer will help with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data: Bar Plot with Distribution Bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since that we have prepared our data and calculated fuzzy percentiles, we can now use the following code to create a bar plot that depicts the (fuzzy) median wage for each subcategory. Similar to what we did above, we want to compare the median wage for our binary race variable relative to the quarter after apprenticeship completion. Since the comparison variable is `binary_race`, that is what we will input in the `fill` parameter. \n",
    "\n",
    "Furthermore, we use the `geom_errorbar()` function to add distribution bars that reflect the (fuzzy) 25th and 75th percentiles for wages. \n",
    "\n",
    "> Note: Just because you use the `geom_errorbar()` function does not mean you have to depict standard errors. You may use it to depict other distribution information such as the 25th and 75th percentiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_2 <- Figure_2_data %>%\n",
    "    ggplot(aes(x = Quarters_Relative_to_Completion, \n",
    "               y = fuzzy_median, \n",
    "               fill = binary_race)) +\n",
    "    geom_bar(stat=\"identity\", position='dodge') +\n",
    "    # adding distribution bars\n",
    "    geom_errorbar(aes(ymin = fuzzy_25, \n",
    "                      ymax = fuzzy_75),\n",
    "                width = .2,                 \n",
    "                position = position_dodge(.9)) +\n",
    "    scale_fill_manual(\"Binary Race Variable\", values = binary_value_color) +\n",
    "    labs(\n",
    "        x = 'Quarter Relative to Completion', # labelling x axis\n",
    "        y = 'Fuzzy Median Percentile Values', # labelling y axis\n",
    "        # Add a title that conveys the main takeaway of the graph\n",
    "        title = 'REDACTED', # The \\n splits the title into two lines \n",
    "        caption = 'Source: RAPIDS and UI Wage data' # cite the source of your data\n",
    "        ) \n",
    "Figure_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the font size using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_2 <- Figure_2 +\n",
    "   theme(\n",
    "        legend.text = element_text(size = 24), # legend text font size\n",
    "        legend.title = element_text(size = 24), # legend title font size\n",
    "        axis.text.x = element_text(size = 24), # x axis label font size\n",
    "        axis.title.x = element_text(size = 24), # x axis title font size\n",
    "        axis.text.y = element_text(size = 24), # y axis label font size\n",
    "        axis.title.y = element_text(size = 24) # y axis title font size\n",
    "    )\n",
    "\n",
    "# Display the graph that we just created\n",
    "Figure_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent Employed over Time\n",
    "\n",
    "From these first two visuals, we can build one tracking the percent employed by quarter relative to completion, broken down by the binary race variable. The graph will depict the percent of individuals from our cohort employed relative to completion in a line graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Export\n",
    "\n",
    "We will adhere to the following steps in preparing this visualization for export:\n",
    "\n",
    "1. Redact values \n",
    "    - Values with employer counts below 3 and/or individual counts below 11 must be removed\n",
    "\n",
    "2. Round values\n",
    "\n",
    "    - Counts below 1000 should be rounded to the nearest ten\n",
    "    - Counts above or equal to 1000 should be rounded to the nearest hundred\n",
    "    - Wages must be rounded to the nearest hundred\n",
    "   \n",
    "3. Find and round percent\n",
    "    - Must be derived from the rounded counts - round to the nearest percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for Export\n",
    "\n",
    "We already have the number of individuals employed by quarter relative to apprenticeship completion for our subgroup of interest (**Figure_2_data**), and we need to combine that with the total amount of individuals by the binary race indicator from our original cohort because we want to find the proportion of our cohort of apprenticeship completers that have a wage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total by binary_race\n",
    "total_race <- cohort %>%\n",
    "    count(binary_race) %>%\n",
    "    # rename n to n_total\n",
    "    rename(n_total = n)\n",
    "\n",
    "total_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join figure_2_data with total_race to get data for proportions by binary_race and quarter relative to graduation\n",
    "# then apply rounding and suppression\n",
    "Figure_3_data <- Figure_2_data %>%\n",
    "    # ignore extraneous columns\n",
    "    select(-starts_with(\"fuzzy\")) %>%\n",
    "    inner_join(total_race, by = 'binary_race') %>%\n",
    "    mutate(\n",
    "        n_individuals_rounded = ifelse(individuals > 999, round(individuals, digits = -2), round(individuals, digits = -1)),\n",
    "        n_total_rounded = ifelse(n_total > 999, round(n_total, digits = -2), round(n_total, digits = -1)),\n",
    "        prop_rounded = ifelse(individuals < 11 | employers < 3, NA, round(n_individuals_rounded/n_total_rounded, digits = 2))\n",
    "    )\n",
    "Figure_3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated the proportion of our original cohort that has a wage. For example, in the first quarter after completing an apprenticeship, REDACTED of Non-White individuals from our original cohort are employed.\n",
    "\n",
    "Notice that there is also at least a difference of 11 individuals between the true count by our binary race variable and quarter relative to apprenticeship completion and the total amount of individuals by binary race indicator that completed an apprenticeship, so no further redaction is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this data frame as a csv, as it will be required for the export submission process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(Figure_3_data, \"Data/Figure_3_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data: Line Plot\n",
    "\n",
    "We can create a line plot with `geom_line()`. Here, to dictate the color, we will use the `color` attribute as opposed to `fill`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_3 <- Figure_3_data %>%\n",
    "    ggplot(aes(x = Quarters_Relative_to_Completion, y = prop_rounded, color = binary_race)) +\n",
    "    geom_line(size = 1.3) + \n",
    "    geom_point(size = 5) + \n",
    "    scale_color_manual(\"Binary Race Variable\", values = binary_value_color) +\n",
    "    labs(\n",
    "        # Labelling x axis\n",
    "        x = 'Quarter Relative to Completion', \n",
    "        # Labelling y axis\n",
    "        y = 'Proportion Employed', \n",
    "        # Add a title that conveys the main takeaway of the graph\n",
    "        title = 'REDACTED', \n",
    "        # cite the source of your data\n",
    "        caption = 'Source: RAPIDS and UI Wages data'\n",
    "    )\n",
    "\n",
    "Figure_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As currently constructed, the plot is a bit misleading, as the auto-generated limits on the y-axis make it appear as though non-white people were never employed after completing their apprenticeship. In addition to modifying the font sizes, we will update the range of the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_3 <- Figure_3 + \n",
    "   theme(\n",
    "        legend.text = element_text(size = 24), # legend text font size\n",
    "        legend.title = element_text(size = 24), # legend title font size\n",
    "        axis.text.x = element_text(size = 24), # x axis label font size\n",
    "        axis.title.x = element_text(size = 24), # x axis title font size\n",
    "        axis.text.y = element_text(size = 24), # y axis label font size\n",
    "        axis.title.y = element_text(size = 24) # y axis title font size\n",
    "    ) +\n",
    "    ylim(0, 1) # update range of y-axis \n",
    "\n",
    "# Display the graph that we just created\n",
    "Figure_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employment Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final visualization in this notebook is a heatmap displaying our cohort of apprenticeship completers' employment patterns by quarter relative to completion, as we will focus on the 5 most common patterns. We do not use a heatmap in the classic way where each \"box\" in the map corresponds to a proportion or number. Instead, we will use the heatmap as a format to display employment patterns, as we will colorcode each box depending on if the pattern has or does not have employment in a specific quarter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Export\n",
    "To export a figure depicting unique patterns of employment, we will need to take the following steps:\n",
    "- Find the number of unique employers and individuals that are associated with each employment pattern\n",
    "- Select only those patterns that are associated with at least 11 invididuals and 3 employers\n",
    "- Round the counts of individuals and population (`pop`)\n",
    "- Create a percent variable using the rounded counts of individuals and population (`pop`)\n",
    "- Round the percent\n",
    "- Make the visual\n",
    "\n",
    "First, though, we will need to create our underlying analytical frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for Export\n",
    "\n",
    "We already have our linked cohort-wages data frame, where each row is a separate person/quarter combination. However, this data frame (**cohort_wages**) only contains entries of employment. First, we will get the information of the rest of the cohort by joining this data frame to our original **cohort** data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wage information for everyone in cohort\n",
    "# if they don't have any wage information, they will have NA for all of the cohort_wages-specific variables\n",
    "all_cohort_wages <- cohort %>%\n",
    "    left_join(cohort_wages, by = c('apprnumber', 'binary_race', 'race'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check, there should only be five possible values for the variable **Quarters_Relative_to_Completion**: 1, 2, 3, 4, and NA (if they were not in the wage records at all during this time frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm potential values of Quarters_Relative_to_Completion\n",
    "all_cohort_wages %>% \n",
    "    distinct(Quarters_Relative_to_Completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these individuals who did not match to **cohort_wages**, we will set the **Quarters_Relative_to_Completion** to 1, so that we will eventually be able to have one observation for each individual/quarter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cohort_wages <- all_cohort_wages %>%\n",
    "    mutate(\n",
    "        Quarters_Relative_to_Completion = ifelse(is.na(Quarters_Relative_to_Completion), 1, Quarters_Relative_to_Completion)\n",
    "    )\n",
    "\n",
    "# confirm potential values of Quarters_Relative_to_Completion\n",
    "all_cohort_wages %>% \n",
    "    distinct(Quarters_Relative_to_Completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all individuals, as well as instances of all desired `Quarters_Relative_to_Completion` values, we can leverage the tidyverse's `complete()` function, which will add additional rows for any person/quarter combinations that do not currently exist. \n",
    "\n",
    "> Note: If the person/quarter combination did not appear in the wage records, we will set their **Primary_Employer_Wages** value to NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete file\n",
    "completed <- all_cohort_wages %>%\n",
    "    complete(apprnumber, Quarters_Relative_to_Completion, fill=list(Primary_Employer_Wages=NA))\n",
    "\n",
    "# see that n should be a multiple of n_dist\n",
    "completed %>%\n",
    "    summarize(\n",
    "        n = n(),\n",
    "        n_inds = n_distinct(apprnumber),\n",
    "        test = n_inds*4 == n\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created **completed**, we just need to aggregate and manipulate the data frame so that each column is a quarter, and each observation is an individual, with the corresponding columns indicating whether the individual was employed in the given quarter. To start, let's create a variable `wage_ind`, which will be \"yes\" if the individual had greater than 0 earnings in the quarter, and \"no\" otherwise. Additionally, for each in column manipulation, we will change each `quarter_number` value from 1, 2, 3, 4 to Q1, Q2, Q3, Q4 and call this variable `quarter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wage_ind and quarter variables\n",
    "patterns <- completed %>%\n",
    "    mutate(\n",
    "        wage_ind = ifelse(Primary_Employer_Wages <= 0 | is.na(Primary_Employer_Wages), \"no\", \"yes\"),\n",
    "        quarter = paste(\"Q\", Quarters_Relative_to_Completion, sep=\"\")\n",
    "    )\n",
    "\n",
    "head(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to figure out how to \"pivot\" the data frame so that each column is a value of **quarter**, with **wage_ind** values for the **apprnumber** values. To do so, we will use `pivot_wider()`, which allows us to take a tidy data frame (one observation per row) and \"widen\" it so that each column becomes values from what was previously a single column (**quarter**) and the rows are occupied by those from a corresponding column (**wage_ind**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most common employment patterns\n",
    "patterns_wide <- patterns %>%\n",
    "    select(apprnumber, quarter, wage_ind) %>%\n",
    "    pivot_wider(names_from = quarter, values_from = wage_ind) %>%\n",
    "    # after pivtor can summarize by each quarter column to find amount of people per row\n",
    "    group_by(Q1, Q2, Q3, Q4) %>%\n",
    "    summarize(\n",
    "        ind_cnt = n_distinct(apprnumber)\n",
    "    ) %>%\n",
    "    arrange(desc(ind_cnt)) %>%\n",
    "    ungroup()\n",
    "\n",
    "head(patterns_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have the true number of individuals per pattern, we do not have any information about the number of employers. We can find the number of employers by taking the first three lines of the previous cell, which find the pattern for each individual:\n",
    "\n",
    "    patterns %>%\n",
    "        select(apprnumber, quarter, wage_ind) %>%\n",
    "        pivot_wider(names_from = quarter, values_from = wage_ind)\n",
    "        \n",
    "And join that back to **cohort_wages** to get the employer information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_info <- patterns %>%\n",
    "    select(apprnumber, quarter, wage_ind) %>%\n",
    "    pivot_wider(names_from = quarter, values_from = wage_ind) %>% \n",
    "    left_join(cohort_wages, by = 'apprnumber') %>% \n",
    "    # find number of aggregate primary employers per grouping\n",
    "    group_by(Q1, Q2, Q3, Q4) %>%\n",
    "    summarize(\n",
    "        emp_cnt = n_distinct(Federal_EIN, na.rm=T) #setting na.rm=T so we don't count NA employers\n",
    "    )\n",
    "\n",
    "head(emp_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top patterns with employer info\n",
    "patterns_wide %>% \n",
    "    inner_join(emp_info, by = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can visualize this information, we need to apply the appropriate rounding and suppression rules.\n",
    "\n",
    "> Note: **emp_cnt** technically only tracks primary employers - if there were a case where a pattern would be getting suppressed based on the employer count and not the individual count, that would warrant a separate query to load information on all employers in a quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rounding and suppression\n",
    "# ignore all redacted patterns\n",
    "Figure_4_data <- patterns_wide %>% \n",
    "    inner_join(emp_info, by = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")) %>%\n",
    "    mutate(\n",
    "        n_ind_cnt_rounded = ifelse(ind_cnt > 999, round(ind_cnt, digits = -2), round(ind_cnt, digits = -1)),\n",
    "        n_total = sum(ind_cnt),\n",
    "        n_total_rounded = ifelse(n_total > 999, round(n_total, digits = -2), round(n_total, digits = -1)),\n",
    "        prop_rounded = ifelse(ind_cnt < 11 | (emp_cnt < 3 & emp_cnt > 0), NA, round(n_ind_cnt_rounded/n_total_rounded, digits = 2)), # don't want to redact 0 emp_cnt for the no (x4) pattern\n",
    "        percent_rounded = percent(prop_rounded, digits = .01)\n",
    "    ) %>%\n",
    "    filter(!is.na(prop_rounded))\n",
    "\n",
    "Figure_4_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the table has been prepared, let's save it as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(Figure_4_data, \"Data/Figure_4_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data: Heat map\n",
    "\n",
    "We are going to convert the data back into a long format using the `pivot_longer()` before we can use the data as an input to `geom_tile()`, the function for creating heatmaps in `ggplot2`. Before doing so, let's save a vector of the rounded counts and percentages for each pattern for future reference in the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save counts to use later in the heatmap - we cannot use the counts or percents as an index, as there could be duplicate values \n",
    "counts_percent_rounded <- Figure_4_data %>%\n",
    "    mutate(\n",
    "        counts_pcts = paste(Figure_4_data$n_ind_cnt_rounded, \"(\", Figure_4_data$percent_rounded,\")\")\n",
    "    ) %>%\n",
    "    pull(counts_pcts)\n",
    "\n",
    "counts_percent_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame so that each row corresponds to a pattern/quarter/employment status observation\n",
    "# seq_along() will create a vector to track each pattern\n",
    "Figure_4_data_long <- Figure_4_data %>%\n",
    "    mutate(\n",
    "        Pattern = seq_along(1:nrow(Figure_4_data))\n",
    "    ) %>%\n",
    "    select(starts_with(\"Q\"), Pattern) %>% \n",
    "    pivot_longer(names_to = 'Quarter', values_to = 'Employed', -Pattern) \n",
    "\n",
    "head(Figure_4_data_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create the visualization using the `geom_tile()` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "\n",
    "levels = ordered(1:4)  # specify in which order to add the rows from our wide table (called \"patterns\") \n",
    "                                        \n",
    "\n",
    "Figure_4_data_long$Quarter <- factor(Figure_4_data_long$Quarter, levels=c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")) # we want to preserve the same ordering of rows as they are sorted in the visual from first to last\n",
    "\n",
    "Figure_4 <- Figure_4_data_long %>%\n",
    "    ggplot(aes(x = Quarter, y = ordered(Pattern, levels=rev(levels)))) +                           # sort y-axis according to levels specified above\n",
    "    geom_tile(aes(fill = Employed), colour = 'black') +                                            # fill the table with value from Employed column, create black contouring\n",
    "    scale_fill_brewer(\"Employed\", palette = \"Paired\") +                                            # specify a color palette\n",
    "    scale_x_discrete(position = 'top') +                                                           # include x-axis labels on top of the plot\n",
    "    labs(\n",
    "        # Label Y axis\n",
    "        y = \"Counts (Percentages)\",\n",
    "        # Label X axis\n",
    "        x = \"Quarter After Completion\" ,\n",
    "        # Add a title that reflects the main takeaway of the figure\n",
    "        title = \"REDACTED\",\n",
    "        # Cite the source of your data\n",
    "        caption = \"Source: RAPIDS data and Arkansas UI Wage Records\"\n",
    "    ) +\n",
    "    scale_y_discrete(labels=rev(counts_percent_rounded))  # rename the y-axis ticks to correspond to the counts from the table\n",
    "\n",
    "Figure_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Figure_4 <- Figure_4 + theme(\n",
    "        legend.text = element_text(size = 24), # legend text font size\n",
    "        legend.title = element_text(size = 24), # legend title font size\n",
    "        axis.text.x = element_text(size = 24), # x axis label font size\n",
    "        axis.title.x = element_text(size = 24), # x axis title font size\n",
    "        axis.text.y = element_text(size = 24), # y axis label font size\n",
    "        axis.title.y = element_text(size = 24) # y axis title font size\n",
    "    )\n",
    "\n",
    "# Display the graph that we just created\n",
    "Figure_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Saving Visuals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look at the best ways to export our presentation-ready plots. We use `ggsave()` to save our visuals in a png, jpeg and pdf format without losing quality. In the following example, we only provide code for saving the first figure, but you would want to save each plot that you create for your project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PNG\n",
    "\n",
    "First, we provide an example of using ``ggsave`` with two parameters: `filename` and `plot`.\n",
    "\n",
    "> **Note: In order to save the data in this way, you will need a folder called \"Figures\" in the same folder that contains your code/notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(\n",
    "    filename = sprintf(\"Figures\\\\Figure_1.png\"), # saving path\n",
    "    plot = Figure_1 # plot name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might not be the preferred way of saving a plot since the dimensions of the plot default to 6.67 x 6.67. We suggest looking at the file we just saved in its respective path. You will see how all the labels are cluttered and the graph can not be interpretted. Thus, we recommend using the `width` and `height` parameters in addition to `filename` and `plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(\n",
    "    filename = sprintf(\"Figures\\\\Figure_1.png\"), # saving path\n",
    "    plot = Figure_2, # plot name\n",
    "    width = 20, # width\n",
    "    height = 12 # height\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above saves plots in a format that can be interpretted conveniently. We can reuse this code to save in a JPEG and PDF format below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(\n",
    "    filename = sprintf(\"Figures\\\\Figure_1.jpeg\"), # saving path\n",
    "    plot = Figure_3, # plot name\n",
    "    width = 20, # width\n",
    "    height = 12 # height\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(\n",
    "    filename = sprintf(\"Figures\\\\Figure_4.pdf\"), # saving path\n",
    "    plot = Figure_4, # plot name\n",
    "    width = 20, # width\n",
    "    height = 12 # height\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- Presentation Prep: Advanced, Applied Data Analytics Training, TANF Data Collabarative, 2022\n",
    "- Presentation Prep: Beginner, Applied Data Analytics Training, TANF Data Collabarative, 2022\n",
    "- Prince, Heath, Mian, Rukhshan, Feder, Benjamin, & Barrett, Nathan. (2022, April 4). Data Exploration and Linkage using Texas Unemployment Insurance Data. Zenodo. https://doi.org/10.5281/zenodo.6412649"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
